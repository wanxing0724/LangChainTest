import streamlit as st
from src.agent.doc_rag_bot import graph  # å¯¼å…¥ä½ åšå¥½çš„å›¾

st.title("ğŸ“± æœªæ¥æ‰‹æœº Pro - æ™ºèƒ½å®¢æœ")

# 1. åˆå§‹åŒ–èŠå¤©è®°å½• (Streamlit çš„ Session State)
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# 2. æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# 3. å¤„ç†ç”¨æˆ·è¾“å…¥
if user_input := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ˜¾ç¤ºç”¨æˆ·çš„è¯
    with st.chat_message("user"):
        st.write(user_input)
    st.session_state["messages"].append({"role": "user", "content": user_input})

    # --- å…³é”®ï¼šè°ƒç”¨ä½ çš„ LangGraph ---
    # æ„é€ è¾“å…¥
    inputs = {"messages": st.session_state["messages"]}

    # è°ƒç”¨æ¨¡å‹ (stream_mode=False ç®€å•ç‚¹ï¼Œç›´æ¥æ‹¿ç»“æœ)
    # æ³¨æ„ï¼šè¿™é‡Œ graph.invoke ä¼šå»æ‰§è¡Œä½ çš„ RAG å’Œ LLM
    result = graph.invoke(inputs)

    # è·å– AI çš„æœ€åä¸€æ¡å›å¤
    ai_response = result["messages"][-1].content

    # --- æ˜¾ç¤º AI å›å¤ ---
    with st.chat_message("assistant"):
        st.write(ai_response)
    st.session_state["messages"].append({"role": "assistant", "content": ai_response})